(README in Portuguese-BR - Project in English)
# Feature Engineering pros gringos - Engenharia de Atributos pra n√≥s - O que √©?

<br/>

√â o nome dados a t√©cnica de utilizar o conhecimento sobre o neg√≥cio para selecionar/manipular os atributos a partir dos dados brutos. 

No texto sobre as etapas para a constru√ß√£o de um modelo de Machine Learning, vimos que a primeira etapa consiste em entender o dom√≠nio para, em seguida, realizarmos a coleta e prepara√ß√£o dos dados. √â indispens√°vel que essa sequ√™ncia seja seguida, pois compreender o problema do neg√≥cio √© fundamental para aplicar a melhor abordagem no processo de coleta e manipula√ß√£o dos dados.

√â sempre bom lembrar que os dados n√£o chegam em um formato prop√≠cio para o treinamento do modelo. No primeiro contato entre um profissional de dados e os dados em si, sempre ser√° necess√°rio um processo de limpeza, pois os chamados dados brutos  üí™üé≤ (nome dado aos dados ainda n√£o formatados) podem gerar modelos ineficientes. No entanto qualquer estrat√©gia para editar/excluir ou criar dados em um conjunto deve ser feita com a premissa de que a solu√ß√£o para o problema do neg√≥cio n√£o sera afetada - Essa √© a base da Engenharia de Atributos/ Feature Engineering.

<br/>

#### Algumas  t√©cnicas utilizadas durante o processo de Engenharia de Atributos

Ok, a essa altura j√° compreendemos que precisamos ter o conhecimento do neg√≥cio e do problema que precisa ser resolvido (assim espero üßê). Depois disso, entendemos que precisamos realizar a coleta dos dados, que s√£o a mat√©ria-prima de qualquer modelo. Na sequ√™ncia, realizamos o processo da an√°lise explorat√≥ria, etapa na qual nos aprofundamos nos dados para entender as rela√ß√µes entre eles, poss√≠veis lacunas, etc. Agora, chega a hora de realizarmos o processo de sele√ß√£o dos atributos que ser√£o escolhidos para o treinamento do modelo. Uma vez escolhidos, existem t√©cnicas para garantir que o formato desses mesmos atributos esteja adequado para o processo. Vamos ver mais sobre essas t√©cnicas:

<br/>

## Feature Engineering para sele√ß√£o de atributos üëá:

<br/>

> ### Filtros üî¨

<br/>

> Consiste em aplicarmos t√©cnicas para verificar o qu√£o pr√≥ximo est√° o atributo em rela√ß√£o √† minha vari√°vel de sa√≠da. Por exemplo, em um contexto de an√°lise de fraude, qu√£o determinante √© escolher o atributo "Idade" para determinar se uma compra √© ou n√£o uma fraude? S√£o perguntas que s√£o respondidas atrav√©s da an√°lises correla√ß√£o por exemplo. Importante notar que isso independe de tecnologia √© uma an√°lise humana, √© claro que podemos recorrer a recursos gr√°ficos para visualizar quais atributos fazem ou n√£o sentido para o treinamento do modelo, mas a decis√£o neste caso √© humana, ou seja, a vantagem de utilizar filtros para sele√ß√£o de atributos  √© n√£o demandar custo computacional para o processo - Usar filtros para sele√ß√£o de atributos √© uma t√©cnica comum na comunidade de cientista de dados.

<br/>
<hr/>
<br/>

> ### Wrapper methods 

<br/>

> Essa t√©cnica envolve instanciar um algoritmo e passar a ele nosso conjunto de dados -  O algoritmo divide o conjunto em subconjuntos com diferentes combina√ß√µes de atributos e determina, atrav√©s de um processo de avalia√ß√£o (guarde bem essa parte) qual a melhor combina√ß√£o de atributos para nosso treinamento. Um exemplo de algoritimo que implementa essa t√©cnica √© o RFE do sklearn.

> Abaixo uma imagem extra√≠da deste link da documenta√ß√£o do sklearn onde o RFE aplicou os testes em diferentes subconjuntos e determinou qual o mais eficiente com base no resultado - √â como se fosse um ranking dos atributos  mais importantes para nossa vari√°vel de sa√≠da, cada quadrado representa o qu√£o forte √© a intera√ß√£o entre um determinado atributo e nossa vari√°vel de sa√≠da.

> Um ponto importante sobre wrapper methods √© que podem demandas um alto custo computacional, principalmente quando estamos lidando com um alto n√∫mero de atributos em nosso conjunto, mas ainda sim √© extremamente eficiente e tende a costuma entregar modelos com resultados melhores do que aqueles que foram treinados atrav√©s do processo de filtros.

<br/>
<hr/>
<br/>

> ### Embedded methods 

<br/>

> Enquanto os wrapper methods determinam a melhor combina√ß√£o de atributos atrav√©s de um processo de avalia√ß√£o, os embedded methods fazem isso a partir dos resultados do treinamento do modelo. Isso significa que o treino e a sele√ß√£o de atributos s√£o processos que ocorrem de forma sincronizada nos embedded methods. No scikit-learn, por exemplo, m√©todos como RandomForest (seja para classifica√ß√£o ou regress√£o) j√° contam com t√©cnicas durante o treinamento que determinam quais s√£o os atributos mais relevantes para o modelo, mas isso n√£o significa que ao utilzar modelos RandomForest n√£o devemos nos preocupar com a sele√ß√£o de atributos, embedded methods demandam um alto custo computacional e em conjuntos grandes isso pode ser um problema - Aplicar a filtragem antes do RandomForest para que ele lide com um menor conjunto de atributos √© uma solu√ß√£o apropriada por exemplo.